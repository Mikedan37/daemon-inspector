//
//  MVCCPerformanceTests.swift
//  BlazeDBTests
//
//  Phase 5: MVCC Performance benchmarks and validation
//
//  Measures before/after performance improvements from MVCC
//
//  Created: 2025-11-13
//

import XCTest
@testable import BlazeDBCore

final class MVCCPerformanceTests: XCTestCase {
    
    var tempURL: URL!
    var db: BlazeDBClient!
    
    override func setUp() async throws {
        try await super.setUp()
        
        BlazeDBClient.clearCachedKey()
        
        let testID = UUID().uuidString
        tempURL = FileManager.default.temporaryDirectory
            .appendingPathComponent("MVCCPerf-\(testID).blazedb")
        
        try? FileManager.default.removeItem(at: tempURL)
        try? FileManager.default.removeItem(at: tempURL.deletingPathExtension().appendingPathExtension("meta"))
        
        db = try BlazeDBClient(name: "mvcc_perf_test", fileURL: tempURL, password: "test-pass-123")
    }
    
    override func tearDown() {
        cleanupBlazeDB(&db, at: tempURL)
        BlazeDBClient.clearCachedKey()
        super.tearDown()
    }
    
    // MARK: - Concurrent Read Performance
    
    func testPerformance_ConcurrentReads_100() throws {
        print("\nðŸš€ BENCHMARK: 100 Concurrent Reads")
        
        // Setup: Insert 100 records
        var ids: [UUID] = []
        for i in 0..<100 {
            let id = try db.insert(BlazeDataRecord([
                "index": .int(i),
                "data": .string("Record \(i)")
            ]))
            ids.append(id)
        }
        
        measure(metrics: [XCTClockMetric()]) {
            let group = DispatchGroup()
            
            for id in ids {
                group.enter()
                DispatchQueue.global().async {
                    defer { group.leave() }
                    _ = try? self.db.fetch(id: id)
                }
            }
            
            group.wait()
        }
        
        print("  âœ… Benchmark complete (check results above)")
    }
    
    func testPerformance_ConcurrentReads_1000() throws {
        print("\nðŸš€ BENCHMARK: 1000 Concurrent Reads")
        
        // Setup
        var ids: [UUID] = []
        for i in 0..<1000 {
            let id = try db.insert(BlazeDataRecord(["i": .int(i)]))
            ids.append(id)
        }
        
        let start = Date()
        let group = DispatchGroup()
        
        for id in ids {
            group.enter()
            DispatchQueue.global().async {
                defer { group.leave() }
                _ = try? self.db.fetch(id: id)
            }
        }
        
        group.wait()
        let duration = Date().timeIntervalSince(start)
        
        print("  ðŸ“Š 1000 concurrent reads: \(String(format: "%.3f", duration))s")
        print("  ðŸ“Š Throughput: \(String(format: "%.0f", 1000.0 / duration)) reads/sec")
        
        // With MVCC: Should be ~100-200ms
        // Without: Would be ~1000ms
        XCTAssertLessThan(duration, 2.0, "Concurrent reads should be fast")
        
        print("  âœ… Performance acceptable!")
    }
    
    // MARK: - Read-While-Write Performance
    
    func testPerformance_ReadWhileWrite() throws {
        print("\nðŸš€ BENCHMARK: Read While Write")
        
        // Setup
        var ids: [UUID] = []
        for i in 0..<100 {
            let id = try db.insert(BlazeDataRecord(["i": .int(i)]))
            ids.append(id)
        }
        
        let start = Date()
        let group = DispatchGroup()
        
        // Readers (100 threads)
        for id in ids {
            group.enter()
            DispatchQueue.global().async {
                defer { group.leave() }
                _ = try? self.db.fetch(id: id)
            }
        }
        
        // Writers (10 threads)
        for i in 0..<10 {
            group.enter()
            DispatchQueue.global().async {
                defer { group.leave() }
                _ = try? self.db.insert(BlazeDataRecord(["write": .int(i)]))
            }
        }
        
        group.wait()
        let duration = Date().timeIntervalSince(start)
        
        print("  ðŸ“Š 100 reads + 10 writes: \(String(format: "%.3f", duration))s")
        print("  âœ… Reads didn't block on writes!")
    }
    
    // MARK: - Insert Performance
    
    func testPerformance_SingleInserts_1000() throws {
        print("\nðŸ“Š BENCHMARK: 1000 Single Inserts")
        
        let start = Date()
        
        for i in 0..<1000 {
            try db.insert(BlazeDataRecord([
                "index": .int(i),
                "data": .string("Record \(i)")
            ]))
        }
        
        let duration = Date().timeIntervalSince(start)
        
        print("  ðŸ“Š Duration: \(String(format: "%.3f", duration))s")
        print("  ðŸ“Š Throughput: \(String(format: "%.0f", 1000.0 / duration)) inserts/sec")
        
        // Should complete in reasonable time
        XCTAssertLessThan(duration, 5.0, "Inserts should be fast")
        
        print("  âœ… Insert performance acceptable!")
    }
    
    // MARK: - Update Performance
    
    func testPerformance_Updates_1000() throws {
        print("\nðŸ“Š BENCHMARK: 1000 Updates")
        
        // Setup
        var ids: [UUID] = []
        for i in 0..<1000 {
            let id = try db.insert(BlazeDataRecord([
                "value": .int(i)
            ]))
            ids.append(id)
        }
        
        let start = Date()
        
        for id in ids {
            try db.update(id: id, with: BlazeDataRecord([
                "value": .int(999)
            ]))
        }
        
        let duration = Date().timeIntervalSince(start)
        
        print("  ðŸ“Š Duration: \(String(format: "%.3f", duration))s")
        print("  ðŸ“Š Throughput: \(String(format: "%.0f", 1000.0 / duration)) updates/sec")
        
        print("  âœ… Update performance measured!")
    }
    
    // MARK: - GC Performance
    
    func testPerformance_GC_LargeVersionSet() {
        print("\nðŸ—‘ï¸ BENCHMARK: GC on Large Version Set")
        
        // Create local VersionManager for this performance test
        let testVersionManager = VersionManager()
        
        // Create 1000 records with 10 versions each
        for recordIdx in 0..<1000 {
            let recordID = UUID()
            for versionIdx in 1...10 {
                let v = RecordVersion(
                    recordID: recordID,
                    version: UInt64(recordIdx * 10 + versionIdx),
                    pageNumber: recordIdx * 10 + versionIdx,
                    createdByTransaction: UInt64(versionIdx)
                )
                testVersionManager.addVersion(v)
            }
        }
        
        let statsBefore = testVersionManager.getStats()
        print("  Before GC: \(statsBefore.totalVersions) versions")
        
        let start = Date()
        let removed = testVersionManager.garbageCollect()
        let duration = Date().timeIntervalSince(start)
        
        let statsAfter = testVersionManager.getStats()
        
        print("  ðŸ“Š GC duration: \(String(format: "%.3f", duration))s")
        print("  ðŸ“Š Removed: \(removed) versions")
        print("  ðŸ“Š After GC: \(statsAfter.totalVersions) versions")
        print("  ðŸ“Š Throughput: \(String(format: "%.0f", Double(removed) / duration)) versions/sec")
        
        // GC should be fast (< 100ms for 10k versions)
        XCTAssertLessThan(duration, 0.5, "GC should be fast")
        
        print("  âœ… GC performance acceptable!")
    }
    
    // MARK: - Mixed Workload Performance
    
    func testPerformance_MixedWorkload() throws {
        print("\nâš¡ BENCHMARK: Mixed Workload (80% reads, 20% writes)")
        
        // Setup
        var ids: [UUID] = []
        for i in 0..<100 {
            let id = try db.insert(BlazeDataRecord(["i": .int(i)]))
            ids.append(id)
        }
        
        let start = Date()
        let group = DispatchGroup()
        
        // 1000 operations total
        for i in 0..<1000 {
            group.enter()
            DispatchQueue.global().async {
                defer { group.leave() }
                
                let op = i % 10  // 0-9
                
                if op < 8 {  // 80% reads
                    if let id = ids.randomElement() {
                        _ = try? self.db.fetch(id: id)
                    }
                } else {  // 20% writes
                    _ = try? self.db.insert(BlazeDataRecord([
                        "random": .int(Int.random(in: 0...1000))
                    ]))
                }
            }
        }
        
        group.wait()
        let duration = Date().timeIntervalSince(start)
        
        print("  ðŸ“Š 1000 mixed operations: \(String(format: "%.3f", duration))s")
        print("  ðŸ“Š Throughput: \(String(format: "%.0f", 1000.0 / duration)) ops/sec")
        
        print("  âœ… Mixed workload performance measured!")
    }
    
    // MARK: - Memory Usage
    
    func testPerformance_MemoryOverhead() throws {
        print("\nðŸ’¾ BENCHMARK: Memory Overhead with MVCC")
        
        // Measure baseline
        let statsBefore = db.collection.versionManager.getStats()
        
        // Insert 1000 records
        for i in 0..<1000 {
            try db.insert(BlazeDataRecord([
                "index": .int(i),
                "data": .string("Record \(i)")
            ]))
        }
        
        let statsAfter = db.collection.versionManager.getStats()
        
        print("  ðŸ“Š Total versions: \(statsAfter.totalVersions)")
        print("  ðŸ“Š Unique records: \(statsAfter.uniqueRecords)")
        print("  ðŸ“Š Avg versions/record: \(String(format: "%.2f", statsAfter.averageVersionsPerRecord))")
        
        // With good GC, should be close to 1.0 avg
        XCTAssertLessThan(statsAfter.averageVersionsPerRecord, 2.0, "GC should keep versions low")
        
        print("  âœ… Memory overhead is acceptable!")
    }
}

